{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo y procesamiento de la data"
      ],
      "metadata": {
        "id": "Oa8fYZSvirvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ],
      "metadata": {
        "id": "OhETaeoKiRqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cIOEmb7oipmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga de datos"
      ],
      "metadata": {
        "id": "2Nn9qaIpi7CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías necesarias\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# Cargar los datos de entrenamiento y prueba\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Verificar la carga de datos\n",
        "print(f'Número de documentos en el conjunto de entrenamiento: {len(newsgroups_train.data)}')\n",
        "print(f'Número de documentos en el conjunto de prueba: {len(newsgroups_test.data)}')\n",
        "\n",
        "# Mostrar un ejemplo de los datos\n",
        "print(\"\\nEjemplo de documento del conjunto de entrenamiento:\")\n",
        "print(newsgroups_train.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1PrCf6NnrJv",
        "outputId": "fc2407f5-73f3-4edd-9840-a023aa3b5bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de documentos en el conjunto de entrenamiento: 11314\n",
            "Número de documentos en el conjunto de prueba: 7532\n",
            "\n",
            "Ejemplo de documento del conjunto de entrenamiento:\n",
            "I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn\n",
        "tfidfvect = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "yQT2C_WBppbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "newsgroups_train.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "oBJh0uhSckvx",
        "outputId": "da3c3ee7-187f-4116-ccbc-04a1e2a089ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador (obtener el vocabulario y calcular el vector IDF) y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ],
      "metadata": {
        "id": "-QPKCp11cp-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ],
      "metadata": {
        "id": "k0J7VD7vdDMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZgR3gNjdoM_",
        "outputId": "304e1299-c273-4a3b-b255-cef5546e2fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-faMHbVreL6g",
        "outputId": "b70023c5-b910-4c68-dc34-0180563090d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 4811\n",
        "print(newsgroups_train.data[idx])"
      ],
      "metadata": {
        "id": "j0Tv36L-tnOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ],
      "metadata": {
        "id": "shXJwzTvuTPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHvTh6bXwfkD",
        "outputId": "377789d0-6527-477f-e4a7-1ae8670d23d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.70930477, 0.67474953, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSWdiujowh3w",
        "outputId": "7d048fbd-f760-4e72-c6ae-4036165d2216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4811,  6635,  4253, ...,  1534, 10055,  4750])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ],
      "metadata": {
        "id": "Ub7O4lK5wk5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "21X_4Am5wm6H",
        "outputId": "f77b3a20-ab90-43a4-8e4e-40d1fd7c4ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'talk.politics.misc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA06p6-0wpYp",
        "outputId": "391beb9f-b1d8-4830-83c9-255ca2130438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo de clasificación Naïve Bayes"
      ],
      "metadata": {
        "id": "0NG1Mng-wt-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ULXnCNBowwy9",
        "outputId": "d76f4ffa-d46c-4be5-efc8-c290aecbc32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "pe2qs84Ew21l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGJhetEPdA4",
        "outputId": "65c0f9be-9a63-4153-8e34-e4e7053e247a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desafío 1"
      ],
      "metadata": {
        "id": "HKiT7y5EnfRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vectorizar documentos.\n",
        "Tomar 5 documentos al azar y medir similaridad con el resto de los documentos. Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido la similaridad según el contenido del texto y la etiqueta de clasificación."
      ],
      "metadata": {
        "id": "YQdWoPC0nq1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar 5 índices aleatorios\n",
        "np.random.seed(42)  # Para reproducibilidad\n",
        "random_indices = np.random.choice(len(newsgroups_train.data), size=5, replace=False)\n",
        "\n",
        "# Obtener los textos y etiquetas correspondientes\n",
        "random_documents = [newsgroups_train.data[idx] for idx in random_indices]\n",
        "random_labels = [newsgroups_train.target[idx] for idx in random_indices]\n",
        "\n",
        "# Mostrar los textos seleccionados y sus etiquetas\n",
        "for i, text in enumerate(random_documents):\n",
        "    print(f\"Documento {i+1}, Etiqueta: {newsgroups_train.target_names[random_labels[i]]}\\n\")\n",
        "    print(text)\n",
        "    print(\"-------------------------------------------------------------\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8TbhT0Mm0Gj",
        "outputId": "80450299-306c-4d93-868a-a50a71226a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento 1, Etiqueta: misc.forsale\n",
            "\n",
            "For Sale:\n",
            "\n",
            "    Roland TR-606 Drum Machine\n",
            "    Near Mint Condition (no scratches, fully operational).\n",
            "    Sorry no Manuals.\n",
            "    Asking $200 US + shipping\n",
            "\n",
            "    Mirage Rack Mount Sampler\n",
            "    Minor Scratches around rack ear screws\n",
            "    with Advanced Sampling Option, 32 Disks\n",
            "      and both manuals\n",
            "    It's a long story, but I *may* have the Turtle Beach Vision, sample\n",
            "        editing software for the IBM PC.\n",
            "    Asking $400 US + shipping\n",
            "\n",
            "Send all e-mail requests to:  barsz@bnr.ca\n",
            "\n",
            "Regards,\n",
            "-------------------------------------------------------------\n",
            "\n",
            "Documento 2, Etiqueta: comp.windows.x\n",
            "\n",
            "I posted this a while ago and didn't recieve one reply, and now we\n",
            "have another bug report on the same subject. Can anybody help me out?\n",
            "\n",
            "How can you ensure that accelerators work the same independent of\n",
            "case?  What I want is Ctrl+O and Ctrl+o to both be accelerators on one\n",
            "menu entry.\n",
            "\n",
            "In ORA Vol. 6, in the section on accelerators it says \"For information\n",
            "on how to specify translation tables see Vol. 4...\", this is so you\n",
            "know what to put for the XmNaccelerator resource.  If you go to\n",
            "Vol. 4 it says, \"Likewise, if a modifier is specified, there is\n",
            "nothing to prohibit other modifiers from being present as well. For\n",
            "example, the translation:\n",
            "\n",
            "\tShift<Key>q:\tquit()\n",
            "\n",
            "will take effect even if the Ctrl key is held down at the same time as\n",
            "the Shift key (and the q key).\n",
            "\n",
            "This implies to me that setting XmNaccelerator to Ctrl<Key>o should do\n",
            "what I want, but it doesn't, it doesn't work if the user presses the\n",
            "control key, the shift key, and the o key.\n",
            "\n",
            "Is it possible to supply > 1 accelerator for a menu entry? Keep in\n",
            "mind when answering this question that when using Motif you can't use\n",
            "XtInstallAccelerators().\n",
            "\n",
            "I am using Motif 1.1.3 on a DECstation 5000 but I have also tried it\n",
            "on an HP using Motif 1.1.3 and 1.2.\n",
            "\n",
            "\n",
            "-------------------------------------------------------------\n",
            "\n",
            "Documento 3, Etiqueta: talk.politics.misc\n",
            "\n",
            "\n",
            "\n",
            "Of course, free trade and slavery don't make much sense together in\n",
            "a phrase anyway.  Perhaps Mr. Depken meant, \"low import tariffs,\" but\n",
            "that is quite a bit less than \"free trade.\"\n",
            "-------------------------------------------------------------\n",
            "\n",
            "Documento 4, Etiqueta: rec.sport.hockey\n",
            "\n",
            "MIGHTY ONES GET MIGHTIER:\n",
            "\n",
            "TPS, the Finnish Champions 1992/3, are getting still stronger!\n",
            "\n",
            "I just heard some news, according to which TPS has acquired\n",
            "the next Finnish hockey superstar(??) Jere Lehtinen from Kiekko-Espoo!\n",
            "\n",
            "There are also some rumours about Erik Kakko (Reipas) and Marko Jantunen\n",
            "(KalPa) being traded to TPS. Both of this players are currently on the\n",
            "Finnish olympic team. I think that Jantunen is drafted to the NHL, too.\n",
            "\n",
            "BTW. Is Juha Yl|nen (centre, HPK) drafted by the Jets?? During last year\n",
            "he has reached the top level among Finnish centres. He had very good\n",
            "playoff games against TPS!\n",
            "\n",
            "  Hannu\n",
            "-------------------------------------------------------------\n",
            "\n",
            "Documento 5, Etiqueta: comp.os.ms-windows.misc\n",
            "\n",
            "\n",
            "Apparently not. Many people complain about the confusion that\n",
            "results from the filemanager/progman split. It's just a basic\n",
            "flaw.\n",
            "-------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcular similaridad con el resto de los documentos"
      ],
      "metadata": {
        "id": "sjohF69gn4XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = []\n",
        "for i, idx in enumerate(random_indices):\n",
        "    print(f\"Documento {i+1} (Etiqueta: {newsgroups_train.target_names[random_labels[i]]})\\n\")\n",
        "    print(newsgroups_train.data[idx])\n",
        "    print(\"\\nDocumentos más similares:\\n\")\n",
        "\n",
        "    # Calcular similaridad coseno con respecto a todos los documentos\n",
        "    cossim = cosine_similarity(X_train[idx], X_train).flatten()\n",
        "    # Ordenar los índices por similaridad descendente (excluyendo el propio documento)\n",
        "    sorted_indices = np.argsort(cossim)[::-1][1:6]\n",
        "\n",
        "    for j, sim_idx in enumerate(sorted_indices):\n",
        "        print(f\"Similitud: {cossim[sim_idx]}\")\n",
        "        print(f\"Etiqueta: {newsgroups_train.target_names[y_train[sim_idx]]}\")\n",
        "        #print(newsgroups_train.data[sim_idx])\n",
        "        #print(\"-------------------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab6U3dfZK5th",
        "outputId": "f5dc5dec-c567-467e-b76b-3722f18c9196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento 1 (Etiqueta: misc.forsale)\n",
            "\n",
            "For Sale:\n",
            "\n",
            "    Roland TR-606 Drum Machine\n",
            "    Near Mint Condition (no scratches, fully operational).\n",
            "    Sorry no Manuals.\n",
            "    Asking $200 US + shipping\n",
            "\n",
            "    Mirage Rack Mount Sampler\n",
            "    Minor Scratches around rack ear screws\n",
            "    with Advanced Sampling Option, 32 Disks\n",
            "      and both manuals\n",
            "    It's a long story, but I *may* have the Turtle Beach Vision, sample\n",
            "        editing software for the IBM PC.\n",
            "    Asking $400 US + shipping\n",
            "\n",
            "Send all e-mail requests to:  barsz@bnr.ca\n",
            "\n",
            "Regards,\n",
            "\n",
            "Documentos más similares:\n",
            "\n",
            "Similitud: 0.1971248842399524\n",
            "Etiqueta: misc.forsale\n",
            "Similitud: 0.19347705705696125\n",
            "Etiqueta: misc.forsale\n",
            "Similitud: 0.1618054234829718\n",
            "Etiqueta: misc.forsale\n",
            "Similitud: 0.15496775940587007\n",
            "Etiqueta: misc.forsale\n",
            "Similitud: 0.14591636102214595\n",
            "Etiqueta: misc.forsale\n",
            "Documento 2 (Etiqueta: comp.windows.x)\n",
            "\n",
            "I posted this a while ago and didn't recieve one reply, and now we\n",
            "have another bug report on the same subject. Can anybody help me out?\n",
            "\n",
            "How can you ensure that accelerators work the same independent of\n",
            "case?  What I want is Ctrl+O and Ctrl+o to both be accelerators on one\n",
            "menu entry.\n",
            "\n",
            "In ORA Vol. 6, in the section on accelerators it says \"For information\n",
            "on how to specify translation tables see Vol. 4...\", this is so you\n",
            "know what to put for the XmNaccelerator resource.  If you go to\n",
            "Vol. 4 it says, \"Likewise, if a modifier is specified, there is\n",
            "nothing to prohibit other modifiers from being present as well. For\n",
            "example, the translation:\n",
            "\n",
            "\tShift<Key>q:\tquit()\n",
            "\n",
            "will take effect even if the Ctrl key is held down at the same time as\n",
            "the Shift key (and the q key).\n",
            "\n",
            "This implies to me that setting XmNaccelerator to Ctrl<Key>o should do\n",
            "what I want, but it doesn't, it doesn't work if the user presses the\n",
            "control key, the shift key, and the o key.\n",
            "\n",
            "Is it possible to supply > 1 accelerator for a menu entry? Keep in\n",
            "mind when answering this question that when using Motif you can't use\n",
            "XtInstallAccelerators().\n",
            "\n",
            "I am using Motif 1.1.3 on a DECstation 5000 but I have also tried it\n",
            "on an HP using Motif 1.1.3 and 1.2.\n",
            "\n",
            "\n",
            "\n",
            "Documentos más similares:\n",
            "\n",
            "Similitud: 0.486613796114652\n",
            "Etiqueta: comp.windows.x\n",
            "Similitud: 0.4460332701597368\n",
            "Etiqueta: comp.windows.x\n",
            "Similitud: 0.39578890014661333\n",
            "Etiqueta: comp.os.ms-windows.misc\n",
            "Similitud: 0.3415874180649132\n",
            "Etiqueta: comp.sys.mac.hardware\n",
            "Similitud: 0.34060461070623116\n",
            "Etiqueta: sci.crypt\n",
            "Documento 3 (Etiqueta: talk.politics.misc)\n",
            "\n",
            "\n",
            "\n",
            "Of course, free trade and slavery don't make much sense together in\n",
            "a phrase anyway.  Perhaps Mr. Depken meant, \"low import tariffs,\" but\n",
            "that is quite a bit less than \"free trade.\"\n",
            "\n",
            "Documentos más similares:\n",
            "\n",
            "Similitud: 0.1680450728749686\n",
            "Etiqueta: misc.forsale\n",
            "Similitud: 0.15350177200168336\n",
            "Etiqueta: talk.politics.misc\n",
            "Similitud: 0.12648705480381722\n",
            "Etiqueta: rec.sport.baseball\n",
            "Similitud: 0.12544214368902656\n",
            "Etiqueta: sci.crypt\n",
            "Similitud: 0.12475303695564655\n",
            "Etiqueta: rec.sport.hockey\n",
            "Documento 4 (Etiqueta: rec.sport.hockey)\n",
            "\n",
            "MIGHTY ONES GET MIGHTIER:\n",
            "\n",
            "TPS, the Finnish Champions 1992/3, are getting still stronger!\n",
            "\n",
            "I just heard some news, according to which TPS has acquired\n",
            "the next Finnish hockey superstar(??) Jere Lehtinen from Kiekko-Espoo!\n",
            "\n",
            "There are also some rumours about Erik Kakko (Reipas) and Marko Jantunen\n",
            "(KalPa) being traded to TPS. Both of this players are currently on the\n",
            "Finnish olympic team. I think that Jantunen is drafted to the NHL, too.\n",
            "\n",
            "BTW. Is Juha Yl|nen (centre, HPK) drafted by the Jets?? During last year\n",
            "he has reached the top level among Finnish centres. He had very good\n",
            "playoff games against TPS!\n",
            "\n",
            "  Hannu\n",
            "\n",
            "Documentos más similares:\n",
            "\n",
            "Similitud: 0.23435973179367328\n",
            "Etiqueta: rec.sport.hockey\n",
            "Similitud: 0.23287758094235747\n",
            "Etiqueta: alt.atheism\n",
            "Similitud: 0.22189610631172457\n",
            "Etiqueta: rec.sport.hockey\n",
            "Similitud: 0.2101320583427964\n",
            "Etiqueta: rec.sport.hockey\n",
            "Similitud: 0.17825788572859247\n",
            "Etiqueta: rec.sport.hockey\n",
            "Documento 5 (Etiqueta: comp.os.ms-windows.misc)\n",
            "\n",
            "\n",
            "Apparently not. Many people complain about the confusion that\n",
            "results from the filemanager/progman split. It's just a basic\n",
            "flaw.\n",
            "\n",
            "Documentos más similares:\n",
            "\n",
            "Similitud: 0.17818572193017512\n",
            "Etiqueta: comp.graphics\n",
            "Similitud: 0.17022438034487905\n",
            "Etiqueta: comp.os.ms-windows.misc\n",
            "Similitud: 0.13659550843781618\n",
            "Etiqueta: comp.os.ms-windows.misc\n",
            "Similitud: 0.1321018951343532\n",
            "Etiqueta: rec.sport.hockey\n",
            "Similitud: 0.12569151660698769\n",
            "Etiqueta: sci.electronics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Clasificación Naïve Bayes\n",
        "Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación (f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial y ComplementNB."
      ],
      "metadata": {
        "id": "fvxIhz3wRHe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(vectorizer_params, model_type, model_params):\n",
        "    # Vectorización\n",
        "    vectorizer = TfidfVectorizer(**vectorizer_params)\n",
        "    X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
        "    X_test = vectorizer.transform(newsgroups_test.data)\n",
        "\n",
        "    # Selección del modelo\n",
        "    if model_type == 'MultinomialNB':\n",
        "        model = MultinomialNB(**model_params)\n",
        "    elif model_type == 'ComplementNB':\n",
        "        model = ComplementNB(**model_params)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model type. Choose 'MultinomialNB' or 'ComplementNB'.\")\n",
        "\n",
        "    # Entrenamiento y predicción\n",
        "    model.fit(X_train, newsgroups_train.target)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluación\n",
        "    f1 = f1_score(newsgroups_test.target, y_pred, average='macro')\n",
        "    return f1"
      ],
      "metadata": {
        "id": "-bnAFfA5RaLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diferentes parámetros del vectorizador"
      ],
      "metadata": {
        "id": "QUsZFsLGbCR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros del vectorizador para probar\n",
        "vectorizer_params_list = [\n",
        "    {'max_df': 0.5, 'min_df': 2, 'ngram_range': (1, 1), 'stop_words': 'english'},\n",
        "    {'max_df': 0.7, 'min_df': 5, 'ngram_range': (1, 2), 'stop_words': 'english'},\n",
        "    {'max_df': 0.8, 'min_df': 3, 'ngram_range': (1, 1), 'stop_words': None},\n",
        "    {'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 3), 'stop_words': 'english'}\n",
        "]\n",
        "\n",
        "# Parámetros del modelo Naïve Bayes para probar\n",
        "model_params = [\n",
        "    {},\n",
        "    {'alpha': 0.5},\n",
        "    {'alpha': 1.0, 'fit_prior': False}\n",
        "]\n",
        "\n",
        "best_f1_score = 0\n",
        "best_params = None\n",
        "\n",
        "for vectorizer_params in vectorizer_params_list:\n",
        "    for params in model_params:\n",
        "        for model_type in ['MultinomialNB', 'ComplementNB']:\n",
        "            f1 = train_and_evaluate(vectorizer_params, model_type, params)\n",
        "            if f1 > best_f1_score:\n",
        "                best_f1_score = f1\n",
        "                best_params = (vectorizer_params, model_type, params)\n",
        "\n",
        "print(f\"Mejor f1-score: {best_f1_score}\")\n",
        "print(f\"Mejores parámetros: {best_params}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA4BHDGtSIoz",
        "outputId": "e0ffcf52-c292-401f-a853-983ef5d9ed8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor f1-score: 0.7072715088603252\n",
            "Mejores parámetros: ({'max_df': 1.0, 'min_df': 1, 'ngram_range': (1, 3), 'stop_words': 'english'}, 'ComplementNB', {'alpha': 0.5})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matriz documento-término\n",
        "Transponer la matriz documento-término. De esa manera se obtiene una matriz término-documento que puede ser interpretada como una colección de vectorización de palabras."
      ],
      "metadata": {
        "id": "jyzfxgQEbzYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorización\n",
        "tfidfvect = TfidfVectorizer()\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "\n",
        "# Transponer la matriz\n",
        "X_train_transposed = X_train.transpose()\n",
        "\n",
        "print(f'Tipo de X_train: {type(X_train)}')\n",
        "print(f'Tipo de X_train_transposed: {type(X_train_transposed)}')\n",
        "print(f'Shape de X_train: {X_train.shape}')\n",
        "print(f'Shape de X_train_transposed: {X_train_transposed.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfcnRjCzdy5E",
        "outputId": "37502725-45d5-4b32-fdc3-8eb97d6285e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de X_train: <class 'scipy.sparse._csr.csr_matrix'>\n",
            "Tipo de X_train_transposed: <class 'scipy.sparse._csc.csc_matrix'>\n",
            "Shape de X_train: (11314, 101631)\n",
            "Shape de X_train_transposed: (101631, 11314)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el índice de una palabra en particular\n",
        "word = 'car'\n",
        "word_index = tfidfvect.vocabulary_.get(word, -1)\n",
        "\n",
        "if word_index != -1:\n",
        "    # Obtener la fila correspondiente a la palabra\n",
        "    word_vector = X_train_transposed.getrow(word_index).toarray().flatten()\n",
        "    print(f'Vector de la palabra \"{word}\":\\n', word_vector)\n",
        "\n",
        "    # Mostrar los documentos donde esta palabra tiene mayor importancia\n",
        "    top_docs_indices = word_vector.argsort()[::-1][:5]\n",
        "    for idx in top_docs_indices:\n",
        "        print(f'\\nDocumento {idx} (Importancia: {word_vector[idx]}):')\n",
        "        print(newsgroups_train.data[idx])\n",
        "else:\n",
        "    print(f'La palabra \"{word}\" no se encuentra en el vocabulario.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlKIOm4dbmpp",
        "outputId": "0c47ea45-45d7-4ba9-efdc-21a00aa6452d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector de la palabra \"car\":\n",
            " [0.40464699 0.         0.         ... 0.         0.         0.        ]\n",
            "\n",
            "Documento 8266 (Importancia: 0.5287256881150304):\n",
            "\n",
            "Definitely!\n",
            "\n",
            "Safety is an important criterium for me when buying a car. I won't buy a \n",
            "small car like a Civic or whatever.\n",
            "\n",
            "Great = Safety + Handling + Speed  -  for me\n",
            "\n",
            "Seems to me that you would be more \"dead\" in a small car than a large car \n",
            "after an accident.\n",
            "\n",
            "Documento 8013 (Importancia: 0.46008568969406555):\n",
            "\n",
            "If you don't already know it, you should call the bank/credit union/\n",
            "finance company that holds the loan on your present car and get the\n",
            "current payoff cost.\n",
            "\n",
            "If you are trading in your current car on the new car, subtract the\n",
            "payoff amount from the trade-in the dealer is giving you.  (If this\n",
            "turns out to be a negative number, you need to reconsider the deal.)\n",
            "Subtract this difference from the price of the new car.  This is the\n",
            "size of the loan you will need for the new car.\n",
            "\n",
            "The dealer will take care of paying off the loan on your old car out\n",
            "of the money you give them when you pick up your new car.\n",
            "\n",
            "At least that's how it worked for me 5 years ago in Ohio...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Documento 8540 (Importancia: 0.44656404990398263):\n",
            "\n",
            "Poor Matthew.   A million posters to call \"you car drivers\" and he\n",
            "chooses me, a non car owner.\n",
            "\n",
            "Documento 7993 (Importancia: 0.4425021341721087):\n",
            "I bought a car with a defunct engine, to use for parts\n",
            "for my old but still running version of the same car.\n",
            "\n",
            "The car I bought has good tires.\n",
            "\n",
            "Is there anything in particular that I should do to\n",
            "store the defunct car long-term?  I'd hate to have\n",
            "parts of it go bad.  Someone has told me it's bad\n",
            "for the tires to not move the car once-in-a-while.\n",
            "Is this true?   Do I need some props to take the\n",
            "weight of the tires?\n",
            "\n",
            "Best to reply by mail, I am getting spotty news delivery.\n",
            "\n",
            "Documento 0 (Importancia: 0.4046469916999256):\n",
            "I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transponer la matriz documento-término y analizar similaridad entre palabras\n",
        "X_train_transposed = X_train.transpose()\n",
        "\n",
        "def analyze_word_similarity(X, vocabulary, words):\n",
        "    for word in words:\n",
        "        word_index = vocabulary.get(word, -1)\n",
        "        if word_index != -1:\n",
        "            word_vector = X.getrow(word_index).toarray().flatten()\n",
        "            print(f'Vector de la palabra \"{word}\":\\n', word_vector)\n",
        "\n",
        "            top_words_indices = word_vector.argsort()[::-1][:5]\n",
        "            for idx in top_words_indices:\n",
        "                term = idx2word[idx]\n",
        "                print(f'\\nPalabra {term} (Importancia: {word_vector[idx]}):')\n",
        "        else:\n",
        "            print(f'La palabra \"{word}\" no se encuentra en el vocabulario.')\n",
        "\n",
        "# Obtener el diccionario índice-palabra\n",
        "idx2word = {v: k for k, v in tfidfvect.vocabulary_.items()}\n",
        "\n",
        "# Seleccionar 5 palabras para analizar\n",
        "words_to_analyze = ['car', 'computer', 'space', 'health', 'government']\n",
        "\n",
        "# Analizar similaridad de palabras\n",
        "analyze_word_similarity(X_train_transposed, tfidfvect.vocabulary_, words_to_analyze)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDYezyS6eFGb",
        "outputId": "eead8f89-cef8-4c5d-a6b1-1cfb0d4fe1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector de la palabra \"car\":\n",
            " [0.40464699 0.         0.         ... 0.         0.         0.        ]\n",
            "\n",
            "Palabra 4km (Importancia: 0.5287256881150304):\n",
            "\n",
            "Palabra 496 (Importancia: 0.46008568969406555):\n",
            "\n",
            "Palabra 4xl (Importancia: 0.44656404990398263):\n",
            "\n",
            "Palabra 48us (Importancia: 0.4425021341721087):\n",
            "\n",
            "Palabra 00 (Importancia: 0.4046469916999256):\n",
            "Vector de la palabra \"computer\":\n",
            " [0.         0.         0.04674622 ... 0.         0.         0.        ]\n",
            "\n",
            "Palabra 4trt (Importancia: 0.3716229236610804):\n",
            "\n",
            "Palabra 0s9 (Importancia: 0.3307479091216156):\n",
            "\n",
            "Palabra 4d50 (Importancia: 0.3221025403419712):\n",
            "\n",
            "Palabra 1200x900 (Importancia: 0.3122356589269776):\n",
            "\n",
            "Palabra 5967 (Importancia: 0.3102918554114527):\n",
            "Vector de la palabra \"space\":\n",
            " [0.         0.         0.         ... 0.         0.26016747 0.        ]\n",
            "\n",
            "Palabra 636s (Importancia: 0.5824354403360952):\n",
            "\n",
            "Palabra 4100 (Importancia: 0.5612189836679569):\n",
            "\n",
            "Palabra 150multidisk (Importancia: 0.508380770881835):\n",
            "\n",
            "Palabra 1663 (Importancia: 0.43974582032499554):\n",
            "\n",
            "Palabra 2pl75u (Importancia: 0.4221049370666876):\n",
            "Vector de la palabra \"health\":\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "Palabra 2476v (Importancia: 0.3640332043141199):\n",
            "\n",
            "Palabra 49ers (Importancia: 0.3397638234732268):\n",
            "\n",
            "Palabra 116305 (Importancia: 0.3200049536770555):\n",
            "\n",
            "Palabra 5d2w (Importancia: 0.3081686719522322):\n",
            "\n",
            "Palabra 13qst44 (Importancia: 0.2980306825246025):\n",
            "Vector de la palabra \"government\":\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "Palabra 4824 (Importancia: 0.3321712245791552):\n",
            "\n",
            "Palabra 0loz (Importancia: 0.3218355934264718):\n",
            "\n",
            "Palabra 3lkxez (Importancia: 0.32118232467500535):\n",
            "\n",
            "Palabra 492 (Importancia: 0.3191080714027623):\n",
            "\n",
            "Palabra 05rov (Importancia: 0.31812955063870785):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slack\n",
        "* https://join.slack.com/t/ceaiworkspace/shared_invite/zt-2l9un8yte-yWrXdu7msfCwr32VG6RIgQ\n",
        "\n",
        "Github\n",
        "* https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/blob/main/clase_1/ejercicios/Desafio_1.ipynb\n",
        "\n",
        "Drive\n",
        "* https://drive.google.com/drive/u/0/folders/1joS44xgaoCKapc44WmkjcZyjWJh4tQz0\n",
        "\n",
        "Colab TP1\n",
        "* https://colab.research.google.com/github/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/blob/main/clase_1/ejercicios/Desafio_1.ipynb\n"
      ],
      "metadata": {
        "id": "6Kx60a3cgUGp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d9xObsVhlhTs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}